<div align="center">

# âš•ï¸ NHCX Insurance FHIR Utility

**A production-ready microservice that converts Indian health insurance policy PDFs into NHCX-compliant FHIR R4 bundles using AI-powered extraction.**

![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB?style=flat-square&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.110%2B-009688?style=flat-square&logo=fastapi)
![React](https://img.shields.io/badge/React-18-61DAFB?style=flat-square&logo=react&logoColor=black)
![FHIR R4](https://img.shields.io/badge/FHIR-R4-E15C27?style=flat-square)
![NHCX](https://img.shields.io/badge/NHCX-Compliant-1565C0?style=flat-square)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [End-to-End Pipeline](#-end-to-end-pipeline)
- [Why These Tools?](#-why-these-tools)
- [Multi-LLM Architecture](#-multi-llm-architecture)
- [FHIR Bundle Structure](#-fhir-r4-bundle-structure)
- [API Reference](#-api-reference)
- [Technology Stack](#-technology-stack)
- [Configuration](#-configuration)
- [Installation & Setup](#-installation--setup)
- [Running the Application](#-running-the-application)
- [Project Structure](#-project-structure)

---

## ğŸ¯ Overview

Indian health insurance PDFs (sold under IRDAI guidelines and processed through the **NHCX** â€” National Health Claim Exchange) contain dense, unstructured text about plan types, benefit limits, exclusions, co-pays, and TPA details. Translating this into a machine-readable, interoperable format requires:

1. High-quality OCR that retains document structure
2. AI that understands Indian insurance terminology
3. Clinical mapping that aligns extracted medical conditions and benefits directly to **SNOMED CT** codes
4. A standards-compliant FHIR mapper that captures every clinical and financial nuance

This utility automates all four stages, exposing the result via a REST API and a premium browser UI.

---

## ğŸ”„ End-to-End Pipeline

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                        USER (Browser / API)                          â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  1. Upload PDF
                                 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  STAGE 1 â€” PDF â†’ Structured Markdown (OCR)                          â”‚
 â”‚                                                                      â”‚
 â”‚  Fast path: pdftext (digital PDFs â€” all IRDAI/NHCX filed docs)      â”‚
 â”‚  Slow path: Marker ML models (scanned / image-only PDFs)            â”‚
 â”‚  â€¢ Preserves tables, headings, and benefit schedules                 â”‚
 â”‚  â€¢ Runs on CPU (fp32) or GPU (fp16), configurable via config.yaml   â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  2. Structured Markdown
                                 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  STAGE 2 â€” Markdown Pruning (policy_pruner)                         â”‚
 â”‚                                                                      â”‚
 â”‚  â€¢ Removes boilerplate sections (ToC, glossary, arbitration, etc.)  â”‚
 â”‚  â€¢ Keeps only clinically and financially relevant content            â”‚
 â”‚  â€¢ Reduces LLM token usage by ~40â€“60%, cutting cost and latency     â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  3. Pruned Markdown
                                 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  STAGE 3 â€” Structured Data Extraction (LLM)                         â”‚
 â”‚                                                                      â”‚
 â”‚  â€¢ System prompt instructs the LLM to fill a strict JSON schema     â”‚
 â”‚    (insurance_fhir_mapping.json) â€” no invented keys allowed         â”‚
 â”‚  â€¢ Extracts: plan name, type, aliases, period, insurer, TPA,        â”‚
 â”‚    networks, coverages, benefits, limits, exclusions, costs         â”‚
 â”‚  â€¢ Swappable across 5 providers via a single config.yaml change     â”‚
 â”‚    (OpenAI Â· Gemini Â· Ollama Â· Groq Â· AWS Bedrock)                  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  4. Extracted JSON
                                 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  STAGE 4 â€” FHIR R4 Bundle Generation (insurance_plan_fhir_mapper)  â”‚
 â”‚                                                                      â”‚
 â”‚  Resources built:                                                    â”‚
 â”‚  â€¢ Organization (Insurer)  â€” meta.profile, IRDAI identifier         â”‚
 â”‚  â€¢ Organization (TPA)      â€” IRDAI licence number                   â”‚
 â”‚  â€¢ Organization[] (Network hospitals)                                â”‚
 â”‚  â€¢ InsurancePlan           â€” alias, language, narrative, period,    â”‚
 â”‚                              networks, coverages, benefit limits,    â”‚
 â”‚                              exclusion & condition extensions,       â”‚
 â”‚                              plan-level costs & applicability        â”‚
 â”‚  â€¢ Bundle (collection)     â€” language=en-IN, timestamp              â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  5. FHIR Bundle (JSON)
                                 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  RESPONSE                                                            â”‚
 â”‚  â€¢ extracted_data  â€” structured intermediate JSON (auditable)       â”‚
 â”‚  â€¢ fhir_bundle     â€” NHCX-compliant R4 Bundle ready for submission  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ Why These Tools?

### ğŸ–¹ Dual-Path PDF Extraction

Most PDF parsing libraries (`pdfplumber`, `PyMuPDF`) struggle with complex, multi-column insurance documents. The service uses a tiered approach:

- **Fast path** â€” `pdftext` extracts text from digital PDFs instantly with no ML overhead. All standard IRDAI/NHCX-filed documents take this path.
- **Slow path** â€” `marker-pdf` (a deep-learning OCR pipeline built on `transformers` and `torch`) fires only for scanned / image-only PDFs. It detects document layout, preserves table structure as Markdown, and is configurable via `marker.*` settings in `config.yaml`.

### ğŸ“„ `insurance_fhir_mapping.json` â€” Schema-Guided Extraction

Rather than writing fragile regex patterns, the LLM is guided by a **strict JSON schema template** stored in `config/insurance_fhir_mapping.json`. The system prompt instructs the model:

```
You MUST NOT invent new JSON keys, group data under new headers, or change the schema.
Replace the instruction text inside the template values with extracted data.
If any field is not found, set it to null or [] â€” do not omit the key.
```

This approach:
- Makes the output **deterministic and parseable** â€” the mapper always receives the same shape of JSON
- Lets you **extend the schema** without touching Python code â€” just add a new key with an instruction string
- Provides a **clear audit trail** â€” the `extracted_data` field in the API response contains the raw LLM output before FHIR mapping

### âš™ï¸ `config.yaml` + `.env` â€” Layered Configuration

The settings system uses a **priority chain** (highest â†’ lowest):

```
Environment Variables  â†’  .env file  â†’  config.yaml  â†’  Pydantic defaults
```

| Layer | Purpose |
|---|---|
| `config.yaml` | Non-secret settings: LLM provider, model names, Marker worker counts |
| `.env` | Secrets: API keys for OpenAI, Gemini, Groq, AWS credentials |
| Environment variables | CI/CD overrides without file changes |

Switching providers requires **one line change** in `config.yaml`:
```yaml
llm:
  provider: "gemini"   # â† change to "openai", "ollama", "grok", or "bedrock"
```

### ğŸ¥ SNOMED CT Integration

The FHIR mapping engine integrates a local **SNOMED CT Dictionary** located at `src/core/snomed_dictionary.json`. During resource building, extracted clinical terms are cross-referenced against this dictionary. When a match is found, the mapper automatically assigns the official SNOMED code and applies the `http://snomed.info/sct` system URI to the resulting FHIR `CodeableConcept` elements.

---

## ğŸ¤– Multi-LLM Architecture

The service is designed to be **LLM-agnostic** from day one. A single abstract interface drives all providers:

```
LLMService (Abstract Base Class)
â”‚
â”œâ”€â”€ _OpenAICompatibleService  â† shared async chat.completions logic
â”‚   â”œâ”€â”€ OpenAILLMService      â€” GPT-4 Turbo via OpenAI API
â”‚   â”œâ”€â”€ OllamaLLMService      â€” any open model (Llama 3.1, Mistralâ€¦) running locally
â”‚   â””â”€â”€ GrokLLMService        â€” Llama 3 70B via Groq's ultra-fast inference API
â”‚
â”œâ”€â”€ GeminiLLMService          â€” Gemini Flash via Google AI SDK (non-OpenAI protocol)
â””â”€â”€ BedrockLLMService         â€” Claude / Nova / Llama on AWS Bedrock via boto3
```

### Why five providers?

| Provider | Best For |
|---|---|
| **OpenAI (GPT-4 Turbo)** | Highest accuracy for complex policy language |
| **Gemini Flash** | High speed + long context window at low cost |
| **Groq (Llama 3 70B)** | Sub-second latency for real-time demos |
| **Ollama (local)** | Air-gapped / on-premise deployments â€” zero data leaves your machine |
| **AWS Bedrock (Claude / Nova)** | Enterprise compliance, existing AWS infrastructure |

### Health Checks on Startup

Every provider has a **dedicated health check** (`src/health_check.py`) that runs when the server starts. If the configured provider is unreachable or misconfigured, the application **refuses to start** with a clear error message â€” preventing silent failures in production.

---

## ğŸ“¦ FHIR R4 Bundle Structure

A typical output bundle contains the following resources:

```
Bundle (collection, language: en-IN)
â”œâ”€â”€ Organization  [Insurer]
â”‚   â”œâ”€â”€ meta.profile â†’ ABDM StructureDefinition/Organization
â”‚   â”œâ”€â”€ identifier   â†’ IRDAI insurer registry (use: "official")
â”‚   â””â”€â”€ telecom      â†’ phone Â· email Â· website
â”‚
â”œâ”€â”€ Organization  [TPA]
â”‚   â”œâ”€â”€ meta.profile â†’ ABDM StructureDefinition/Organization
â”‚   â””â”€â”€ identifier   â†’ IRDAI TPA licence number
â”‚
â”œâ”€â”€ Organization[]  [Network Hospitals]   (one per network)
â”‚   â””â”€â”€ type â†’ "Healthcare Provider Network"
â”‚
â””â”€â”€ InsurancePlan
    â”œâ”€â”€ meta.profile â†’ ABDM StructureDefinition/InsurancePlan
    â”œâ”€â”€ text         â†’ auto-generated XHTML Narrative
    â”œâ”€â”€ language     â†’ "en-IN"
    â”œâ”€â”€ identifier   â†’ UUID (use: "official")
    â”œâ”€â”€ alias[]      â†’ alternate product / marketing names
    â”œâ”€â”€ status       â†’ "active"
    â”œâ”€â”€ type[]       â†’ ABDM ValueSet/ndhm-insuranceplan-type
    â”œâ”€â”€ ownedBy      â†’ ref â†’ Organization [Insurer]
    â”œâ”€â”€ administeredBy â†’ ref â†’ Organization [TPA]
    â”œâ”€â”€ period       â†’ start / end dates
    â”œâ”€â”€ network[]    â†’ ref â†’ Organization[] [Networks]
    â”œâ”€â”€ coverageArea[] â†’ geographic strings
    â”œâ”€â”€ contact[]
    â”‚   â”œâ”€â”€ purpose  â†’ contactentity-type system
    â”‚   â”œâ”€â”€ name     â†’ HumanName.text
    â”‚   â””â”€â”€ telecom  â†’ phone Â· email
    â”œâ”€â”€ extension[]
    â”‚   â”œâ”€â”€ Claim-SupportingInfoRequirement (POI / POA documents)
    â”‚   â””â”€â”€ Claim-Exclusion (pre-existing diseases, waiting periods)
    â”œâ”€â”€ coverage[]
    â”‚   â””â”€â”€ benefit[]
    â”‚       â”œâ”€â”€ type â†’ CodeableConcept (SNOMED CT where available)
    â”‚       â””â”€â”€ limit[]
    â”‚           â”œâ”€â”€ value  â†’ Quantity (INR / Days / %)
    â”‚           â””â”€â”€ code   â†’ benefit-unit CodeableConcept
    â””â”€â”€ plan[]
        â”œâ”€â”€ identifier â†’ UUID
        â”œâ”€â”€ type       â†’ ndhm-plan-type (Individual / Family Floater)
        â””â”€â”€ specificCost[]
            â””â”€â”€ benefit[]
                â””â”€â”€ cost[]
                    â”œâ”€â”€ type          â†’ benefit-cost-type
                    â”œâ”€â”€ applicability â†’ in-network / out-of-network
                    â””â”€â”€ value         â†’ Quantity
```

---

## ğŸŒ API Reference

All endpoints are prefixed with `/api/v1`.

### Insurance Processing

| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/insurance/process` | Full pipeline: PDF â†’ OCR â†’ LLM â†’ FHIR bundle |
| `POST` | `/insurance/extract-only` | PDF â†’ OCR â†’ LLM extraction only (no FHIR mapping) |
| `POST` | `/insurance/generate-fhir` | JSON â†’ FHIR bundle (when you already have extracted data) |

### System Health

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/insurance/health` | Service health â€” LLM + PDF processor status, API version |

### FHIR Utilities

| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/fhir/validate` | Structural validation of a FHIR bundle (error/warning/info issues) |
| `POST` | `/fhir/bundle-summary` | Human-readable summary card from a FHIR bundle |

Interactive API docs available at `http://localhost:8082/docs` (Swagger UI).

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology | Why |
|---|---|---|
| **Frontend** | React 18, Vanilla CSS | Lightweight; no UI framework overhead |
| **API Server** | FastAPI + Uvicorn | Async-native, auto OpenAPI docs, Pydantic validation |
| **PDF â†’ Text** | `pdftext` (fast) + `marker-pdf` (fallback OCR) | Fast path for digital PDFs; ML fallback for scans |
| **LLM Abstraction** | Abstract base class + Factory | Swap any of 5 providers with one config line |
| **LLM Providers** | OpenAI Â· Gemini Â· Ollama Â· Groq Â· Bedrock | Cloud + on-premise coverage |
| **FHIR Building** | `fhir.resources` (R4) | Type-safe FHIR resource construction; Pydantic-backed |
| **Config** | `config.yaml` + `.env` + Pydantic Settings | Layered; secrets stay out of YAML |
| **Health Checks** | Per-provider sync functions | Fail-fast on startup if LLM is misconfigured |

---

## âš™ï¸ Configuration

### `config.yaml` â€” Non-secret settings

```yaml
llm:
  provider: "gemini"          # openai | ollama | gemini | grok | bedrock

  openai:
    model_name: "gpt-4-turbo"

  ollama:
    base_url: "http://localhost:11434/v1"
    model_name: "llama3.1"

  gemini:
    model_name: "gemini-3-flash"

  grok:
    model_name: "llama3-70b-8192"

  bedrock:
    region_name: "us-east-2"
    model_id: "global.amazon.nova-2-lite-v1:0"

marker:
  workers: 2
  pdftext_workers: 2
  batch_multiplier: 2
  model_precision: "fp32"
  exclude_images: true

pdf_processor:
  min_chars_for_text_pdf: 200   # characters threshold for fast-path selection

### `config/insurance_fhir_mapping.json` â€” Mapping Schema

The extraction logic is driven by the prompt template and JSON schema defined in [config/insurance_fhir_mapping.json](file:///config/insurance_fhir_mapping.json). This file contains the instructions provided to the LLM to ensure the extracted JSON follows a strict structure compatible with the FHIR mapper.
```

### `.env` â€” Secrets (copy `.env.example` â†’ `.env`)

```bash
OPENAI_API_KEY="sk-..."
GOOGLE_API_KEY="AIza..."
GROK_API_KEY="gsk_..."
AWS_ACCESS_KEY_ID="AKIA..."
AWS_SECRET_ACCESS_KEY="..."
```

> **Ollama** requires no API key â€” just have the Ollama service running locally.

---

## ğŸš€ Installation & Setup

### Prerequisites

- Python 3.9+
- Node.js 18+
- `pip`, `venv`, `npm`

### 1. Clone & configure secrets

```bash
git clone <repo-url>
cd InsuranceService

cp .env.example .env
# Edit .env â€” add the API key for your chosen LLM provider
```

### 2. Frontend dependencies

```bash
cd frontend && npm install && cd ..
```

---

## â–¶ï¸ Running the Application

### Using Docker (Recommended)

```bash
docker-compose up -d --build
```

| Service | URL |
|---|---|
| **Frontend** | `http://localhost:8001` |
| **Backend API** | `http://localhost:8082` |
| **Swagger UI** | `http://localhost:8082/docs` |

### Local Development â€” One Command

Each script creates the `.venv` (first run only), installs dependencies, and starts the backend with hot-reload:

**Windows (PowerShell)**
```powershell
.\dev.ps1
```
> If execution policy blocks it, run once: `Set-ExecutionPolicy -Scope CurrentUser RemoteSigned`

**macOS / Linux**
```bash
chmod +x dev.sh && ./dev.sh
```

The backend starts at `http://localhost:8082`. The `.venv` is reused on subsequent runs so only changed packages are reinstalled.

**Frontend** (separate terminal)
```bash
cd frontend && npm start
```
The React dev server starts at `http://localhost:3000` and proxies all `/api/v1/*` calls to `localhost:8082`.

The backend runs the LLM health check on startup â€” it exits immediately if the configured provider is unreachable.

### Batch Processing

Process multiple PDFs in one go:

```bash
python scripts/batch_process.py --input data/input --output data/output
```

---

## ğŸ“‚ Project Structure

```
InsuranceService/
â”‚
â”œâ”€â”€ app.py                              # FastAPI entry point, lifespan, middleware
â”œâ”€â”€ config.yaml                         # Non-secret configuration (LLM, Marker, PDF)
â”œâ”€â”€ .env.example                        # Template for secrets (copy â†’ .env)
â”œâ”€â”€ requirements.txt                    # All Python dependencies (single file)
â”œâ”€â”€ dev.ps1                             # One-command backend setup & run (Windows)
â”œâ”€â”€ dev.sh                              # One-command backend setup & run (macOS/Linux)
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ insurance_fhir_mapping.json     # JSON schema template used in LLM prompt
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ batch_process.py                # CLI tool: batch PDF â†’ FHIR bundle
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                       # Pydantic Settings â€” YAML + .env + env var layers
â”‚   â”œâ”€â”€ constants.py                    # All log messages, error codes, string literals
â”‚   â”œâ”€â”€ health_check.py                 # Per-provider LLM health check functions
â”‚   â”œâ”€â”€ logging_config.py               # Structured logging setup
â”‚   â”œâ”€â”€ middleware.py                   # Request/response logging middleware
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py            # Dual-path OCR: pdftext fast-path + Marker fallback
â”‚   â”‚   â”œâ”€â”€ prompts.py                  # Loads insurance_fhir_mapping.json into system prompt
â”‚   â”‚   â””â”€â”€ snomed_dictionary.json      # Local SNOMED CT terminology dictionary
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ claims.py                   # Insurance processing endpoints (process, extract, generate-fhir)
â”‚   â”‚   â”œâ”€â”€ health.py                   # GET /insurance/health
â”‚   â”‚   â””â”€â”€ fhir.py                     # FHIR utilities (validate, bundle-summary)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ policy_pruner.py            # Strips boilerplate sections from Markdown
â”‚   â”‚   â”œâ”€â”€ fhir/
â”‚   â”‚   â”‚   â”œâ”€â”€ fhir_constants.py       # ABDM/HL7 URLs, system codes, profile URLs
â”‚   â”‚   â”‚   â””â”€â”€ insurance_plan_fhir_mapper.py  # Builds FHIR R4 bundle from dict
â”‚   â”‚   â””â”€â”€ llm/
â”‚   â”‚       â”œâ”€â”€ llm_service.py          # Abstract base + 5 concrete LLM implementations
â”‚   â”‚       â””â”€â”€ llm_factory.py          # Reads config and returns the right LLMService
â”‚   â”‚
â”‚   â””â”€â”€ schemas/
â”‚       â””â”€â”€ insurance_schemas.py        # Pydantic request/response schemas
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_fhir_mapper.py             # Unit tests for FHIR R4 parameters
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ package.json                    # React app; proxy â†’ localhost:8082
    â”œâ”€â”€ nginx.conf                      # Nginx config (listens :8001, proxies /api/ â†’ backend:8082)
    â”œâ”€â”€ Dockerfile                      # Multi-stage build â€” node builder + nginx:alpine
    â””â”€â”€ src/
        â”œâ”€â”€ App.js                      # Layout, state, API wiring
        â”œâ”€â”€ index.js                    # Global CSS, keyframes, responsive grid
        â”œâ”€â”€ api/
        â”‚   â””â”€â”€ claimService.js         # All API call functions
        â””â”€â”€ components/
            â”œâ”€â”€ Upload.js               # Drag-and-drop PDF zone + FHIR toggle
            â”œâ”€â”€ Result.js               # Tabbed JSON viewer, copy/download
            â”œâ”€â”€ StatusBar.js            # Live /health polling (pauses during requests)
            â””â”€â”€ SummaryCard.js          # Plan summary card with FHIR validation issues
```

---

## ğŸ“„ License

This project is developed as part of the **NHCX Hackathon**. All FHIR structure definitions and ValueSet URLs follow [HL7 FHIR R4](https://hl7.org/fhir/R4/) and [ABDM NDHM](https://nrces.in/ndhm/fhir/r4) specifications.
